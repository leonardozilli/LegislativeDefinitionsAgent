{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point-in-Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LegalDefAgent.src.existdb import existdb_handler\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_definition_timeline(definition):\n",
    "    cons = existdb_handler.find_consolidated(definition['metadata'])\n",
    "    if cons:\n",
    "        earliest_entries = {}\n",
    "        for item in cons:\n",
    "            definition_text = item['definition'].strip()\n",
    "            current_entry = earliest_entries.get(definition_text)\n",
    "            \n",
    "            if current_entry is None or item['date'] < current_entry['date']:\n",
    "                earliest_entries[definition_text] = item\n",
    "                \n",
    "        ordered_definitions = sorted(earliest_entries.values(), key=lambda x: x['date'])\n",
    "        for entry in ordered_definitions:\n",
    "            entry['date'] = entry['date'].strftime('%Y-%m-%d')\n",
    "\n",
    "        return ordered_definitions\n",
    "\n",
    "    static = existdb_handler.extract_definition_from_exist(definition['metadata'])\n",
    "    if static:\n",
    "        for entry in static:\n",
    "            entry['date'] = entry['date'].strftime('%Y-%m-%d')\n",
    "        return static\n",
    "    return None\n",
    "\n",
    "df = pl.read_csv('../data/definitions_corpus/definitions.csv')\n",
    "\n",
    "results = []\n",
    "\n",
    "for d in tqdm(df.iter_rows(), total=len(df)):\n",
    "    label = d[3]\n",
    "    dataset = d[4]\n",
    "    doc_id = d[5]\n",
    "    frbr_work = d[6]\n",
    "    frbr_expression = d[7]\n",
    "\n",
    "    dict = {\n",
    "        \"metadata\": {\n",
    "            \"dataset\": dataset,\n",
    "            \"definendum_label\": label,\n",
    "            \"frbr_work\": frbr_work,\n",
    "            \"frbr_expression\": frbr_expression,\n",
    "            \"doc_id\": doc_id\n",
    "        }\n",
    "    }\n",
    "\n",
    "    tl = get_definition_timeline(dict)\n",
    "\n",
    "    if tl and len(tl) > 1:\n",
    "        dict['tl'] = tl\n",
    "        results.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('results.pkl', 'wb') as f:   \n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    if res['metadata']['definendum_label'] == '#marketManipulation':\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "for el in results:\n",
    "    metadata = el['metadata']\n",
    "    for entry in el['tl']:\n",
    "        definendum = re.search(r'^.*?\"\\s?\"?\\s*([^\"]*)\\s*', entry['definition']).group(1).strip()\n",
    "        if entry['definition'].startswith('person'):\n",
    "            definendum = 'person'\n",
    "        elif entry['definition'].startswith('automatic exchange'):\n",
    "            definendum = 'automatic exchange'\n",
    "        records.append({\n",
    "            'Term': definendum,\n",
    "            'Date': entry['date'],\n",
    "            'Definition': entry['definition'],\n",
    "            'Dataset': metadata['dataset'],\n",
    "            'Label': metadata['definendum_label'],\n",
    "            'CELEX': metadata['doc_id'].split('.')[0],\n",
    "            'FRBR_Work': metadata['frbr_work'],\n",
    "            'FRBR_Expression': metadata['frbr_expression']\n",
    "        })\n",
    "\n",
    "df = pl.DataFrame(records)\n",
    "\n",
    "df = df.sort(['Term', 'Date'])\n",
    "\n",
    "#pivot_df = df.pivot(\n",
    "    #values='Definition',\n",
    "    #index='Term',\n",
    "    #columns='Date'\n",
    "#)\n",
    "\n",
    "\n",
    "df.sort('Term')\n",
    "df.to_pandas().to_excel('definitions_with_modifications.xlsx', header=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddf = pl.read_excel('./datasets/point-in-time/definitions_with_modifications.xlsx')\n",
    "df.join(olddf, on=['Term', 'Date', 'Definition'], how='anti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olddf.group_by('Term').agg(pl.len()).join(df.group_by('Term').agg(pl.len()), on='Term', how='left').filter(pl.col('len') != pl.col('len_right'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old from csv\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "result = {}\n",
    "\n",
    "date_pattern = r\"'date':\\s*'([^']+)'\"\n",
    "definition_pattern = r\"'definition':\\s*'([^']+)'\"\n",
    "\n",
    "with open(\"../notebooks/definition_timeline.csv\", \"r\") as f:\n",
    "    file = f.read()\n",
    "    for line in file.split('\\n')[1:]:\n",
    "        definendum = re.search(r'\"\"\\s*([^\"]*)\\s*\"\"', line).group(1).strip()\n",
    "        if definendum not in result:\n",
    "            result[definendum] = {}\n",
    "\n",
    "        tl = {}\n",
    "        for el in line.split('\",\"'):\n",
    "            date_match = re.search(date_pattern, el).group(1)\n",
    "            definition_match = re.search(definition_pattern, el).group(1)\n",
    "            result[definendum][date_match] = definition_match\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Multi-legislation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "\n",
    "cols = ['id',\n",
    " 'definition_text',\n",
    " 'def_n',\n",
    " 'document_id',\n",
    " 'frbr_work',\n",
    " 'frbr_expression']\n",
    "\n",
    "juris_df = defs.group_by(['label', 'dataset']).agg(pl.all()).sort('label').filter(pl.col('label').is_duplicated()).explode(cols)#.group_by('label').agg(pl.all()).sort('label')\n",
    "\n",
    "juris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LegalDefAgent.src.utils import camelcase_to_spaces\n",
    "from pprint import pprint\n",
    "import json\n",
    "\n",
    "z = []\n",
    "\n",
    "for el in juris_df.filter(pl.col('dataset').list.contains('EurLex')).to_dicts():\n",
    "    term = camelcase_to_spaces(el['label'])\n",
    "    num_jurisdictions = len(el['dataset'])\n",
    "    for i in range(num_jurisdictions):\n",
    "        entry = {\n",
    "            \"label\": el['label'],\n",
    "            \"term\": term,\n",
    "            \"dataset\": el['dataset'][i],\n",
    "            \"id\": el['id'][i][0] if el['id'][i] else None,\n",
    "            \"definition_text\": el['definition_text'][i][0] if el['definition_text'][i] else None,\n",
    "            \"def_n\": el['def_n'][i][0] if el['def_n'][i] else None,\n",
    "            \"document_id\": el['document_id'][i][0].split('.')[0] if el['document_id'][i] else None,\n",
    "        }\n",
    "        z.append(entry)\n",
    "    \n",
    "pprint(z)\n",
    "\n",
    "\n",
    "with open('./datasets/legislation_definitions.json', 'w') as f:\n",
    "    json.dump(z, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
